{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"The-Northcap-University-NCU-logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Image Classification Drill\n",
    "\n",
    "\n",
    "Welcome to your drill! Follow the instructions in bold below to complete the drill.\n",
    "\n",
    "------------\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "**Your task is to build an image classifier with Keras and Convolutional Neural Networks for the Fashion MNIST dataset. This data set includes 10 labels of different clothing types with 28 by 28 *grayscale* images. There is a training set of 60,000 images and 10,000 test images.**\n",
    "\n",
    "    Label\tDescription\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "**TASK 1: Run the code below to download the dataset using Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1us/step  \n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "**TASK 2: Use matplotlib to view an image from the data set. It can be any image from the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Select a random image index (you can change this number between 0 and 59999)\n",
    "image_index = 100\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(x_train[image_index], cmap='gray')\n",
    "plt.title(f'Fashion MNIST Sample - Label: {y_train[image_index]}')\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()\n",
    "\n",
    "# Optional: Print the shape of the image to understand its dimensions\n",
    "print(f\"Image shape: {x_train[image_index].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bf7c9c1d68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFFhJREFUeJzt3WtwlFWaB/D/053OhdABwiUgRvGCCqMrOhFUphxHRgcta9FxtLQsF6uswdrVqZ1ZP2ixszXuh92yrFXXWndmNyorVo3OpUZXx6IcNa7ilSEiKwqLKERAIAlEkpCkk748+yHNTICc52369jae/6+KIumnT/qku/95u/u85xxRVRCRfyJhd4CIwsHwE3mK4SfyFMNP5CmGn8hTDD+Rpxh+Ik8x/ESeYviJPFVVzhurlhqtRX05b5LIKwkMYESHJZfrFhR+EVkK4FEAUQBPqOoD1vVrUY9FsqSQmyQiwzpty/m6eb/sF5EogH8HcDWA+QBuEZH5+f48IiqvQt7zLwTwmapuV9URAL8CsKw43SKiUisk/LMB7Brz/e7sZUcQkRUi0i4i7UkMF3BzRFRMhYR/vA8VjpkfrKqtqtqiqi0x1BRwc0RUTIWEfzeA5jHfnwxgT2HdIaJyKST86wHMFZHTRKQawM0AXixOt4io1PIe6lPVlIjcDeAPGB3qW6WqnxStZ0RUUgWN86vqGgBritQXIiojnt5L5CmGn8hTDD+Rpxh+Ik8x/ESeYviJPMXwE3mK4SfyFMNP5CmGn8hTDD+Rpxh+Ik8x/ESeKuvS3RQCCVjFWY9ZfOm4RKc2mvWvvneWs9bwzPsF3XbQ7yZVMWdNkyOF3Xahgh4XS4GP2WE88hN5iuEn8hTDT+Qphp/IUww/kacYfiJPMfxEnuI4/9ecRKNmXVMpsx5ZYO+9uuXOiXb7IXctNrDQbFs1lDHrsVfazXpBY/lB5xAE3K8Q+7haSN+kyoit/XAegUd+Ik8x/ESeYviJPMXwE3mK4SfyFMNP5CmGn8hTBY3zi0gHgH4AaQApVW0pRqeoeMwxYQSP8+/63mSzfuslb5n1d7pPd9a+qJlpttU6s4yq715i1s/6+ZfOWqpjp/3DA+bMB91vQaJTpriL6bTZNt3X5y4ex1T/Ypzk8x1V3V+En0NEZcSX/USeKjT8CuAVEflARFYUo0NEVB6FvuxfrKp7RGQGgFdF5P9Ude3YK2T/KKwAgFpMKPDmiKhYCjryq+qe7P9dAJ4HcMxMDVVtVdUWVW2JoaaQmyOiIso7/CJSLyLxw18DuArAx8XqGBGVViEv+5sAPC+jUx+rADyjqi8XpVdEVHJ5h19VtwM4v4h9oRLIJBIFtR+54JBZ/8Eke059bSTprL0Zsefrf/l6s1lP/4Xdty8ejjtrmQ8vNdtO/dgea2/4cK9Z33/ZbLPe/U33gHxTwHYGU1773FmTntwjzaE+Ik8x/ESeYviJPMXwE3mK4SfyFMNP5CnRIm33m4sGadRFsqRst+cNa5npgMf30E0Xm/Wrf/qGWZ9Xu8es92dqnbURLezs8se2ftusD2yf5KxFRgK2yA4op5vspbc1aR9Xp2xw/+51yzrNtvL4dGfto7ZHcahnV077f/PIT+Qphp/IUww/kacYfiJPMfxEnmL4iTzF8BN5iuP8lSBgO+iCBDy+535g//3//hR7ym6QqLGW9IBWm20PpusLuu3ulHtKbzLgHIMnttlTfg8Z5xAAQCRlP6ZXfudDZ+2GxvVm2wfPOM9ZW6dt6NMejvMTkRvDT+Qphp/IUww/kacYfiJPMfxEnmL4iTxVjF16qVBlPNfiaNsOzTDrBxommvV9KXsL76lR9/La8ciQ2XZOzN78uTvtHscHgGjMvTT4iEbNtv/4jd+b9cS8mFmPib3096XGOgg3bv4rs209tpv1XPHIT+Qphp/IUww/kacYfiJPMfxEnmL4iTzF8BN5KnCcX0RWAbgWQJeqnpu9rBHArwHMAdAB4CZV/ap03aRSmV5jb3NdK+4ttgGgWlJmfU9yirO2behss+2nffY5CEubPjHrSWMs31pnAAgepz8pZj/dE2qfB2Ddq4ub7HH8jWY1d7kc+Z8CsPSoy+4D0KaqcwG0Zb8nohNIYPhVdS2AnqMuXgZgdfbr1QCuK3K/iKjE8n3P36SqewEg+7/9+oyIKk7Jz+0XkRUAVgBALSaU+uaIKEf5Hvk7RWQWAGT/73JdUVVbVbVFVVtiqMnz5oio2PIN/4sAlme/Xg7gheJ0h4jKJTD8IvIsgPcAnC0iu0XkDgAPALhSRLYBuDL7PRGdQALf86vqLY4SF+AvloB1+yVqzz3XlHusPTrFPc4OAN+evMmsd6cbzPrBtP05zuTooLPWn6o12/YM2T/7nJq9Zn3D4BxnbXq1PU5v9RsAOkammfW5NfvM+oOd7vg01x49uHak1JLLnDVd957Zdiye4UfkKYafyFMMP5GnGH4iTzH8RJ5i+Ik8xaW7K0HA0t1SZT9M1lDfrjvmmW2vmGAvUf1uYrZZn17Vb9atabWzanrNtvGmhFkPGmZsrHJPV+5P15ltJ0SGzXrQ731htb3s+E9eu9BZi597wGzbEDOO2cex2zuP/ESeYviJPMXwE3mK4SfyFMNP5CmGn8hTDD+RpzjOXwEkVm3WMwl7vNsybdOIWd+ftpeYnhyxp7ZWByxxbW2FfWnjDrNtd8BY/Iah08x6POreAnx6xB6nb47ZY+2bEs1mfc3AmWb9jmtfc9aebb3SbFv98rvOmqj9eI3FIz+Rpxh+Ik8x/ESeYviJPMXwE3mK4SfyFMNP5KkTa5zfWOJaquzxaokG/J2L2PVMwpjfnbHHuoNo0h6LL8Sj//mYWd+VmmzW9yXtetAS12ljgvn7Q5PMtrURe3vw6VV9Zr0vY58nYOnP2MuKW+sUAMF9v3fqNmftud7vmm2LhUd+Ik8x/ESeYviJPMXwE3mK4SfyFMNP5CmGn8hTgeP8IrIKwLUAulT13Oxl9wP4IYDu7NVWquqaQjtTyPr0QWPlag+7hmpo2UKzvus6+zyCWy/4o7O2LxU3235obGMNAJOMOfEAUB+wvn1C3edf7Bmxtw8PGiu31uUHgBnGeQBptY97XybtvgUJOv9hd8rYU+Av7bUGJj+dV5eOkcuR/ykAS8e5/BFVXZD9V3Dwiai8AsOvqmsB9JShL0RURoW8579bRD4SkVUiUthrJCIqu3zD/wsAZwBYAGAvgIdcVxSRFSLSLiLtSdjvD4mofPIKv6p2qmpaVTMAHgfg/MRKVVtVtUVVW2KoybefRFRkeYVfRGaN+fZ6AB8XpztEVC65DPU9C+ByANNEZDeAnwG4XEQWAFAAHQDuLGEfiagERAP2hi+mBmnURbKkbLc3VtWsmWY9eVqTWe+Z594LfnCmvSn6gmu2mPXbm942693pBrMeE/f5D0H70M+MHTTrr/fON+sTq+zPcazzBC6s6zDbHsy473MAOKnqK7N+72c/cNaaJthj6U+cao9eJzVj1rcm7be48Yj7vJS3Bu01/5+fP91ZW6dt6NMe+wmZxTP8iDzF8BN5iuEn8hTDT+Qphp/IUww/kacqaunu4asvMusz/n67s7agYbfZdn6dPZyWyNhLf1vTSzcPzTbbDmbsLbi3jdjDkL0pe8grKu5hp64Re0rvQzvsZaLbFv6HWf/pnvEmfP5ZpM49lHwgPdFse8NEe2luwH7M7jxlrbN2enWX2falgVlmfU/AlN+mWK9ZnxPrdta+H//UbPs83EN9x4NHfiJPMfxEnmL4iTzF8BN5iuEn8hTDT+Qphp/IU+Ud5xd7ee5F/7zebL4k/omzNqj2FMqgcfygcVvLpCp7mebhpH03dyXtKbtBzqrZ56xd37DRbLv2sUVm/VuJH5n1z6/4L7PeNuTeyro7Zf/eN++4wqxv2Nls1i+es8NZOy/+pdk26NyKeDRh1q1p1gAwkHE/X99P2Oc/FAuP/ESeYviJPMXwE3mK4SfyFMNP5CmGn8hTDD+Rp8q6dHfdzGY947a/c9Zb7/o3s/0zPRc7a8219l6ip1bvN+tTo/Z2z5Z4xB7zPTtmj/m+NHCyWX/j4Dlm/ZvxDmctJvb23pdP+Mys3/6Te8x6qtZeJbpvjvv4kqq3n3sN5x8w6z8683WzXm387gfT9jh+0P0WtAV3EGsNhnjE3hb9oWuud9be63gKvUN7uXQ3Ebkx/ESeYviJPMXwE3mK4SfyFMNP5CmGn8hTgfP5RaQZwNMAZgLIAGhV1UdFpBHArwHMAdAB4CZVNfdMjiSBCZ3u8c2X+haYfTm9zr3W+f6kvT79Hw6dZ9ZPrrO3e7a2mj7TmE8PABsTk836y93fMOsn1dnr13cmJzlrB5L1ZttBY145ADz5yMNm/aFOe93/6xs3OGvnV9vj+Acz9rFpc8B+B/2ZWmctofb6Dr0B5wHEjecDACTVjlbU2OJ7csQ+h6DvvKnOWroz9yU6cjnypwDco6rzAFwM4C4RmQ/gPgBtqjoXQFv2eyI6QQSGX1X3quqG7Nf9ALYAmA1gGYDV2autBnBdqTpJRMV3XO/5RWQOgAsArAPQpKp7gdE/EABmFLtzRFQ6OYdfRCYC+B2AH6tq0CZqY9utEJF2EWlPDQ/k00ciKoGcwi8iMYwG/5eq+lz24k4RmZWtzwIw7s6Hqtqqqi2q2lJVY3/4RETlExh+EREATwLYoqpjP/p9EcDy7NfLAbxQ/O4RUankMi6wGMBtADaJyOF1oFcCeADAb0TkDgA7AdwY9IOiIxnEdw076xm1ZyK+vt89tbWptt9suyC+y6xvHbSHjTYNneSsbag6xWxbF3Vv7w0Ak6rtKcH1Ve77DACmxdy/+2k19lbU1rRXAFifsH+3v57+hlnfmXIvif77gbPMtpsH3fc5AEwJWDJ9U5+7/WDK3jZ9OG1HI5Gyh44n1diP6UWNXzhrW2FvD959vjFN+h2z6RECw6+qbwNwpXJJ7jdFRJWEZ/gReYrhJ/IUw0/kKYafyFMMP5GnGH4iT5V3i+5DQ4i8+aGz/NtXFpvN/2HZb521NwOWt35pnz0u2zdiT22dPsF9anKDMc4OAI0x+7TmoC2+awO2e/4q5T5zcjhiT11NO0dxR+0bdk8XBoB3MnPNejLj3qJ72KgBwedH9IxMM+sn1fU6a/0p93RfAOjobzTr+3vtbbQTE+xovZ0+w1lbOtO9FT0A1HW5H7OI/VQ58rq5X5WIvk4YfiJPMfxEnmL4iTzF8BN5iuEn8hTDT+Spsm7R3SCNukjynwXce6t7i+7T/2ar2Xbh5B1mfUOfPW99pzHumwxYYjoWcS/TDAATYiNmvTZgvLs66p6TH4H9+GYCxvnro3bfgtYaaKhyz2uPR+057xFjG+tcRI3f/Y+9cwr62fGA3zul9nPikkmfO2urdlxqtp10jXtb9XXahj7t4RbdROTG8BN5iuEn8hTDT+Qphp/IUww/kacYfiJPlX+cP3qV+woZew35QgzcsMisL1q53q7H3eOy51R3mm1jsMerawPGs+sj9rBtwngMg/66vz3UbNbTAT/h9a/mmfWkMd7dOdhgto0Z5y/kwtoHYigVsEX3kD3fPxqxc5N4w15rYOpm97kbNWvs56KF4/xEFIjhJ/IUw0/kKYafyFMMP5GnGH4iTzH8RJ4KHOcXkWYATwOYCSADoFVVHxWR+wH8EEB39qorVXWN9bMKnc9fqeQie0+AoZl1Zr3mgD03vP9Uu33D5+59ASLD9kLumf/dYtbpxHI84/y5bNqRAnCPqm4QkTiAD0Tk1WztEVX9l3w7SkThCQy/qu4FsDf7db+IbAEwu9QdI6LSOq73/CIyB8AFANZlL7pbRD4SkVUiMsXRZoWItItIexL2y1siKp+cwy8iEwH8DsCPVbUPwC8AnAFgAUZfGTw0XjtVbVXVFlVticHeD4+Iyien8ItIDKPB/6WqPgcAqtqpqmlVzQB4HMDC0nWTiIotMPwiIgCeBLBFVR8ec/msMVe7HsDHxe8eEZVKLp/2LwZwG4BNIrIxe9lKALeIyAIACqADwJ0l6eEJQNdvMuv25NBgDe/m37awxa/p6yyXT/vfBsZd3N0c0yeiysYz/Ig8xfATeYrhJ/IUw0/kKYafyFMMP5GnGH4iTzH8RJ5i+Ik8xfATeYrhJ/IUw0/kKYafyFMMP5GnyrpFt4h0A/hizEXTAOwvWweOT6X2rVL7BbBv+Spm305V1em5XLGs4T/mxkXaVbUltA4YKrVvldovgH3LV1h948t+Ik8x/ESeCjv8rSHfvqVS+1ap/QLYt3yF0rdQ3/MTUXjCPvITUUhCCb+ILBWRrSLymYjcF0YfXESkQ0Q2ichGEWkPuS+rRKRLRD4ec1mjiLwqItuy/4+7TVpIfbtfRL7M3ncbReSakPrWLCL/IyJbROQTEfnb7OWh3ndGv0K538r+sl9EogA+BXAlgN0A1gO4RVU3l7UjDiLSAaBFVUMfExaRywAcAvC0qp6bvexBAD2q+kD2D+cUVb23Qvp2P4BDYe/cnN1QZtbYnaUBXAfgdoR43xn9ugkh3G9hHPkXAvhMVber6giAXwFYFkI/Kp6qrgXQc9TFywCszn69GqNPnrJz9K0iqOpeVd2Q/bofwOGdpUO974x+hSKM8M8GsGvM97tRWVt+K4BXROQDEVkRdmfG0ZTdNv3w9ukzQu7P0QJ3bi6no3aWrpj7Lp8dr4stjPCPt/tPJQ05LFbVCwFcDeCu7Mtbyk1OOzeXyzg7S1eEfHe8LrYwwr8bQPOY708GsCeEfoxLVfdk/+8C8Dwqb/fhzsObpGb/7wq5P39SSTs3j7ezNCrgvqukHa/DCP96AHNF5DQRqQZwM4AXQ+jHMUSkPvtBDESkHsBVqLzdh18EsDz79XIAL4TYlyNUys7Nrp2lEfJ9V2k7Xodykk92KONfAUQBrFLVfyp7J8YhIqdj9GgPjG5i+kyYfRORZwFcjtFZX50AfgbgvwH8BsApAHYCuFFVy/7Bm6Nvl2P0peufdm4+/B67zH37FoC3AGzCnzcqXonR99eh3XdGv25BCPcbz/Aj8hTP8CPyFMNP5CmGn8hTDD+Rpxh+Ik8x/ESeYviJPMXwE3nq/wHG6/IGFn5KEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "**TASK 3: Normalize the X train and X test data by dividing by the max value of the image arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x_train min value: 0, max value: 255\n",
      "Normalized x_train min value: 0.0, max value: 1.0\n",
      "Original x_test min value: 0, max value: 255\n",
      "Normalized x_test min value: 0.0, max value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Normalize the training and testing data\n",
    "x_train_normalized = x_train / 255.0\n",
    "x_test_normalized = x_test / 255.0\n",
    "\n",
    "# Optional: Verify the normalization\n",
    "print(f\"Original x_train min value: {x_train.min()}, max value: {x_train.max()}\")\n",
    "print(f\"Normalized x_train min value: {x_train_normalized.min()}, max value: {x_train_normalized.max()}\")\n",
    "print(f\"Original x_test min value: {x_test.min()}, max value: {x_test.max()}\")\n",
    "print(f\"Normalized x_test min value: {x_test_normalized.min()}, max value: {x_test_normalized.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Reshape the X arrays to include a 4 dimension of the single channel. Similar to what we did for the numbers MNIST data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x_train shape: (60000, 28, 28)\n",
      "Reshaped x_train shape: (60000, 28, 28, 1)\n",
      "Original x_test shape: (10000, 28, 28)\n",
      "Reshaped x_test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the normalized training and testing data to include channel dimension\n",
    "x_train_reshaped = x_train_normalized.reshape(x_train_normalized.shape[0], 28, 28, 1)\n",
    "x_test_reshaped = x_test_normalized.reshape(x_test_normalized.shape[0], 28, 28, 1)\n",
    "\n",
    "# Optional: Verify the new shapes\n",
    "print(f\"Original x_train shape: {x_train_normalized.shape}\")\n",
    "print(f\"Reshaped x_train shape: {x_train_reshaped.shape}\")\n",
    "print(f\"Original x_test shape: {x_test_normalized.shape}\")\n",
    "print(f\"Reshaped x_test shape: {x_test_reshaped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5: Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original y_train shape: (60000,)\n",
      "One-hot encoded y_train shape: (60000, 10)\n",
      "Original y_test shape: (10000,)\n",
      "One-hot encoded y_test shape: (10000, 10)\n",
      "\n",
      "Example - Original label: 9\n",
      "One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert y_train and y_test to one-hot encoded format\n",
    "y_train_encoded = to_categorical(y_train, num_classes=10)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Optional: Verify the conversion\n",
    "print(f\"Original y_train shape: {y_train.shape}\")\n",
    "print(f\"One-hot encoded y_train shape: {y_train_encoded.shape}\")\n",
    "print(f\"Original y_test shape: {y_test.shape}\")\n",
    "print(f\"One-hot encoded y_test shape: {y_test_encoded.shape}\")\n",
    "\n",
    "# Optional: Show an example\n",
    "print(f\"\\nExample - Original label: {y_train[0]}\")\n",
    "print(f\"One-hot encoded label: {y_train_encoded[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "**TASK 5: Use Keras to create a model consisting of at least the following layers (but feel free to experiment):**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(4,4)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compile the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">589,952</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m589,952\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">591,786</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m591,786\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">591,786</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m591,786\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Create the CNN model\n",
    "model = Sequential([\n",
    "    # 2D Convolutional Layer: 32 filters, 4x4 kernel, input shape is 28x28x1 (grayscale)\n",
    "    Conv2D(filters=32, kernel_size=(4,4), activation='relu', input_shape=(28, 28, 1)),\n",
    "    \n",
    "    # Pooling Layer: 2x2 pool size\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    # Flatten Layer: Converts 2D feature maps to 1D vector\n",
    "    Flatten(),\n",
    "    \n",
    "    # Dense Layer: 128 neurons with ReLU activation\n",
    "    Dense(128, activation='relu'),Xd\n",
    "    \n",
    "    # Output Dense Layer: 10 neurons (one per class) with softmax activation\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Optional: Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "**TASK 6: Train/Fit the model to the x_train set. Amount of epochs is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.7623 - loss: 0.6782 - val_accuracy: 0.8742 - val_loss: 0.3546\n",
      "Epoch 2/8\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.8853 - loss: 0.3196 - val_accuracy: 0.8901 - val_loss: 0.3015\n",
      "Epoch 3/8\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.9024 - loss: 0.2657 - val_accuracy: 0.8597 - val_loss: 0.3652\n",
      "Epoch 4/8\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9125 - loss: 0.2388 - val_accuracy: 0.9049 - val_loss: 0.2676\n",
      "Epoch 5/8\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9251 - loss: 0.2071 - val_accuracy: 0.9073 - val_loss: 0.2568\n",
      "Epoch 6/8\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9348 - loss: 0.1822 - val_accuracy: 0.9122 - val_loss: 0.2519\n",
      "Epoch 7/8\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9410 - loss: 0.1655 - val_accuracy: 0.9101 - val_loss: 0.2517\n",
      "Epoch 8/8\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9435 - loss: 0.1513 - val_accuracy: 0.9076 - val_loss: 0.2716\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x_train_reshaped, \n",
    "    y_train_encoded,\n",
    "    epochs=8,  # You can adjust this number\n",
    "    batch_size=64,  # Common batch size, feel free to modify\n",
    "    validation_split=0.2,  # Use 20% of training data for validation\n",
    "    verbose=1  # Shows progress bar for each epoch\n",
    ")\n",
    "\n",
    "# Optional: Print a message when training is complete\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1802 - acc: 0.9365\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1679 - acc: 0.9395\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1579 - acc: 0.9439\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1502 - acc: 0.9469\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1427 - acc: 0.9496\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1397 - acc: 0.9523\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1312 - acc: 0.9551\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1274 - acc: 0.9559\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1238 - acc: 0.9582\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1201 - acc: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c18a60e400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "**TASK 7: Show the accuracy,precision,recall,f1-score the model achieved on the x_test data set. Keep in mind, there are quite a few ways to do this, but we recommend following the same procedure we showed in the MNIST lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step  \n",
      "Classification Report for Fashion MNIST Test Set:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.84      0.89      0.87      1000\n",
      "     Trouser       0.99      0.98      0.98      1000\n",
      "    Pullover       0.77      0.91      0.83      1000\n",
      "       Dress       0.89      0.94      0.91      1000\n",
      "        Coat       0.83      0.86      0.85      1000\n",
      "      Sandal       0.98      0.98      0.98      1000\n",
      "       Shirt       0.86      0.59      0.70      1000\n",
      "     Sneaker       0.96      0.97      0.96      1000\n",
      "         Bag       0.99      0.98      0.98      1000\n",
      "  Ankle boot       0.97      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.90     10000\n",
      "weighted avg       0.91      0.91      0.90     10000\n",
      "\n",
      "\n",
      "Overall Test Accuracy: 0.9059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_test_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = np.argmax(y_test_encoded, axis=1)  # Convert one-hot encoded test labels back to classes\n",
    "\n",
    "# Define class names for Fashion MNIST (for better readability)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Generate and print the classification report\n",
    "report = classification_report(y_test_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report for Fashion MNIST Test Set:\\n\")\n",
    "print(report)\n",
    "\n",
    "# Optional: Calculate and print overall accuracy separately\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test_encoded, verbose=0)\n",
    "print(f\"\\nOverall Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      1000\n",
      "          1       0.99      0.97      0.98      1000\n",
      "          2       0.88      0.83      0.85      1000\n",
      "          3       0.91      0.91      0.91      1000\n",
      "          4       0.83      0.88      0.85      1000\n",
      "          5       0.97      0.98      0.98      1000\n",
      "          6       0.73      0.76      0.74      1000\n",
      "          7       0.95      0.97      0.96      1000\n",
      "          8       0.99      0.97      0.98      1000\n",
      "          9       0.98      0.94      0.96      1000\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
